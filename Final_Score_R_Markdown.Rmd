---
title: "CollegeFootballScores"
author: "Steven Mazurski"
date: "3/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(stringr)
library(ggplot2)
library(DBI)
library(stats)
library(caret)
library(corrplot)

urlfile<-'https://raw.githubusercontent.com/smazurski/ShinyData/master/Score_Prediction_Data.csv'

Orig_Score_Data <- read_csv(urlfile)

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r distributions}

# view dataset
glimpse(Orig_Score_Data)


# remove non-predictor variables
Orig_Score_Data <- Orig_Score_Data %>%
  select(-GameID, -Offense, -Defense)


# View data distributions
Orig_Score_Data %>%
  keep(is.numeric) %>%
  gather() %>%
  ggplot() +
  geom_histogram(mapping = aes(x=value,fill=key), color="black") +
  facet_wrap(~ key, scales = "free") +
  theme_minimal()


## Distributions look fairly normal. Some variables need to change.

```





```{r corrplot}

# View Corr plot
Orig_Score_Data %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot()

```



```{r new corrplot}

#Remove Year
Orig_Score_Data <- Orig_Score_Data %>%
  select(-Year)


# View Corr plot
Orig_Score_Data %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot()


```




```{r scatterplots}

# Convert Conference and is_Home to Factor 
Orig_Score_Data$is_home <- as.factor(Orig_Score_Data$is_home)
Orig_Score_Data$OffConf <- as.factor(Orig_Score_Data$OffConf)


# View continuous variables in plot
Orig_Score_Data %>%
  keep(is.numeric) %>%
  plot()


```



```{r first_regresssion}
# View in Regression Model
Orig_Score_Model <- lm(Orig_Score_Data$Points~., data = Orig_Score_Data)
summary(Orig_Score_Model)

```




```{r variable importance}
# R-squared is .5316, F-stat = 196
# Variable Importance
imp <- varImp(Orig_Score_Model, scale=FALSE)
imp

```


```{r adjusted model}

# Remove Insignificant Variables with high p-values

Orig_Score_Data <- Orig_Score_Data %>%
  select(-DefRecruitRank, -OffRanking, -OffRecruitRank, -OffRanking)


Orig_Score_Model <- lm(Orig_Score_Data$Points~., data = Orig_Score_Data)
summary(Orig_Score_Model)


# R-squared is .5315, F-stat = 233.5
## Pretty Decent, let's see which variables add the most value to the model
imp <- varImp(Orig_Score_Model, scale=FALSE)
imp


```




```{r feature engineering}

# Remove DFPI and QBR
Orig_Score_Data <- Orig_Score_Data %>%
  select(-QBR)


Orig_Score_Model <- lm(Orig_Score_Data$Points~., data = Orig_Score_Data)
summary(Orig_Score_Model)

# R-squared is .5307, F-stat = 258.6

```



```{r RMSE}
#Let's test the predictions
Score_Data <- Orig_Score_Data


#Split the dataset
test_data_train <- data.frame(Score_Data[1:3400,])
test_data_test <- data.frame(Score_Data[3401:4365,])

# Create Model
lm_train <- lm(test_data_train$Points~., data = test_data_train)

# Make predictions
lm_pred <- predict(lm_train, test_data_test)


#Convert to dataframe and merge for residuals
lm_pred <- data.frame(lm_pred)
lm_pred$Points <- test_data_test$Points
lm_pred <- na.omit(lm_pred)


#RMSE .6133257
sqrt(mean(lm_pred$lm_pred[1:965]-lm_pred$Points[1:965])^2)

```


```{r standard_deviation}

lm_pred <- lm_pred %>%
  mutate(diff=lm_pred-Points)


print("Mean:")
mean(lm_pred$diff)
print("Median:")
median(lm_pred$diff)
# The mean/median predictions distribution are pretty close to zero. Looks like we're slightly
# underestimating the scores

```



```{r ggplot}
ggplot(lm_pred, aes(x=diff)) +
  geom_density(alpha=0.8, color = 'lightblue', fill = 'lightblue') +
  theme_classic()


sd(lm_pred$diff)
 # 1 Standard Deviation = 10.11913 points

```


```{r Lasso}
## Let's try a LASSO regression model

#lasso
library(glmnet)

# Split target variable from features
x <- model.matrix(Score_Data$Points~.,Score_Data)[,-1]
y <- Score_Data$Points

lambda <- 10^seq(10, -2, length = 100)

#split test and training datasets
train=sample(x[1:3400,])
test=(x[3401:4365,])
y.test=y[3401:4365]

# Create Model
lasso.mod=glmnet(x[1:3400,],y[1:3400], alpha=1, lambda = lambda)
plot(lasso.mod)

set.seed(1)
cv.out=cv.glmnet(x[1:3400,],y[1:3400],alpha=1)
plot(cv.out)


```


```{r lasso RMSE}

bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx = x[3401:4365,])

# RMSE: .7227...Slightly lower than linear regression model
sqrt(mean(lasso.pred-y.test)^2)

```


```{r Lasso graphs}

lasso_data <- data.frame(lasso.pred, y.test)

lasso_data <- lasso_data %>%
  mutate(difference=X1-y.test)

mean(lasso_data$difference)
median(lasso_data$difference)
hist(lasso_data$difference)
sd(lasso_data$difference) 
# slightly wider distribution than the multiple regression model,  # 1 SD = 10.12273 points

out=glmnet(x,y,alpha = 1,lambda = lambda)
lasso.coef=predict(out,type = "coefficients", s=bestlam)

lasso.coef

```
